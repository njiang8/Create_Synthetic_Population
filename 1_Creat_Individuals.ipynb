{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import random\n",
    "import pickle #save results\n",
    "from itertools import chain\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1, Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1, Raod Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road = gpd.read_file('Data/Road_line.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2, Demographic data (Census Tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = gpd.read_file('Data/Census_Cleaned.shp').set_index('GEOID10')\n",
    "#check size of census track data\n",
    "len(dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3, Commute Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = pd.read_csv('Data/tract-od.csv.zip',dtype={i:(str if i<2 else int) for i in range(6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4, Workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbp = pd.read_csv('Data/cbp10co.zip')\n",
    "cbp = cbp[(cbp.naics.str.startswith('-'))] #All types of establishments included\n",
    "cbp['fips'] = cbp.fipstate.map(\"{:02}\".format) + cbp.fipscty.map(\"{:03}\".format)\n",
    "cbp = cbp.set_index('fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2, Data PreProcessing\n",
    "#### Add 3 columns on dp (demographics) dataframe\n",
    "* [col1] controls the number of individuals will be generated within each census tract\n",
    "* [col2] the number of workplaces\n",
    "* [col3] the probability for employees(individuals) to be assigned in each workplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Portion\n",
    "\n",
    "Add a column called \"portion\", which controls the number of individuals will be generated within each census tract\n",
    "Set portion to 1, which allows the algorithm generate all individuals living in the census tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp['portion'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The number of workplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_wp(dp, od, cbp):\n",
    "    \"\"\"\n",
    "    calculate number of workplaces for each tract\n",
    "    wp_tract = wp_cty * (tract_employed / county_employed)\n",
    "    \"\"\"\n",
    "    # get the number of employees per tract\n",
    "    dwp = od[['work','S000']].groupby('work').sum()\n",
    "    dwp = pd.merge(dp.portion.to_frame(),dwp,left_index=True,right_index=True,how='left').fillna(0)\n",
    "    #dwp = pd.merge(dp,dwp,left_index=True,right_index=True,how='left').fillna(0)\n",
    "    #dwp = dwp.portion*dwp.S000/10\n",
    "    wp_class = [\"n1_4\",\"n5_9\",\"n10_19\",\"n20_49\",\"n50_99\",\"n100_249\",\"n250_499\",\"n500_999\",\"n1000\",\"n1000_1\",\"n1000_2\",\"n1000_3\",\"n1000_4\"]\n",
    "    dwp['county'] = dwp.index.str[:5]\n",
    "    a = dwp.groupby('county').sum()\n",
    "    a = a.join(cbp[wp_class].sum(axis=1).to_frame('wpcty'))\n",
    "    # note: as Dr. Crooks suggested agents not living in our region included\n",
    "    dwp = (dwp.portion * dwp.S000 / dwp.county.map(a.S000)) * dwp.county.map(a.wpcty)\n",
    "    #dwp = (dwp.S000 / dwp.county.map(a.S000)) * dwp.county.map(a.wpcty)\n",
    "    return dwp.apply(np.ceil).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3, The probability for employees(individuals) to be assigned in each workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_proba(x):\n",
    "    \"\"\"\n",
    "    probability of an employee working in that workplace is lognormal:\n",
    "    http://www.haas.berkeley.edu/faculty/pdf/wallace_dynamics.pdf\n",
    "    \"\"\"\n",
    "    if x == 0: return np.zeros(0)\n",
    "    b = np.random.lognormal(mean=2,size=x).reshape(-1, 1)\n",
    "    return np.sort(normalize(b,norm='l1',axis=0).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Apply Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of workplaces in each track\n",
    "dp['WP_CNT'] = number_of_wp(dp,od,cbp)\n",
    "# each track, the probability distribution for an employee to work there is lognormal\n",
    "# this column has the probability for each workplace and they add up to 1. \n",
    "dp['WP_PROBA'] = dp.WP_CNT.map(wp_proba)\n",
    "dp.sort_index(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3, Synthesizing Population "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3,1 Create individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individuals(tract):\n",
    "    \"\"\"Generate a population of ages and sexes as a DataFrame\n",
    "\n",
    "    Given the number of individuals for 18 age groups of each sex,\n",
    "    return a two column DataFrame of age ([0,89]) and sex ('m','f')\n",
    "    \"\"\"\n",
    "    #portion = tract.geometry.area / tract.Shape_Area # what portion of the tract is included\n",
    "    #age_sex_groups = (tract[22:59].drop('DP0010039') * portion).astype(int)\n",
    "    \n",
    "    age_sex_groups = (tract[22:59].drop('DP0010039')).astype(int)\n",
    "    \n",
    "    dfs=[]\n",
    "    \n",
    "    #code is the index(generated by the enumerate build-in function) of the list \n",
    "    #,which indicates the age and sex group\n",
    "    #code 0~17 male\n",
    "    #code 18~35 female\n",
    "    for code,count in enumerate(age_sex_groups):\n",
    "        base_age = (code % 18)*5\n",
    "        gender = 'm' if code < 18 else 'f'\n",
    "        ages = []\n",
    "        for offset in range(4):\n",
    "            ages.extend([offset+base_age]*(count//5))\n",
    "        ages.extend([base_age+4]*(count-len(ages)))\n",
    "        dfs.append(pd.DataFrame({'code':code, 'age':ages,'sex':[gender]*count}))\n",
    "    df = pd.concat(dfs).sample(frac=1,random_state=123).reset_index(drop=True)\n",
    "    df.index = tract.name + 'i' + df.index.to_series().astype(str)\n",
    "    #df['friends'] = [set()] * len(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_households(tract, people):\n",
    "    #get the amount of each household type\n",
    "    hh_cnt = get_hh_cnts(tract)\n",
    "    #create a empty df to hold indivadual hhold\n",
    "    hholds = pd.DataFrame()\n",
    "    #create a column to in hhold to hold the households types info\n",
    "    hholds['htype'] = np.repeat(hh_cnt.index,hh_cnt)\n",
    "    hholds = hholds[hholds.htype != 6].sort_values('htype',ascending=False).append(hholds[hholds.htype == 6])\n",
    "    \n",
    "    #create member for each households; \n",
    "    #for remaining populating, populate them in households as relatives and those living in group quarter (non-household)\n",
    "    populate_households(tract, people, hholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of household under different household types\n",
    "def get_hh_cnts(tract):\n",
    "    \"\"\"\n",
    "    Eleven household types:\n",
    "    0         h&w (no<18)\n",
    "    1      h&w&ch (ch<18)\n",
    "    2        male (no<18)\n",
    "    3        male (ch<18)\n",
    "    4      female (no<18)\n",
    "    5      female (ch<18)\n",
    "    6     nonfamily group\n",
    "    7       lone male <65\n",
    "    8       lone male >65\n",
    "    9      lone female<65\n",
    "    10     lone female>65\n",
    "    \"\"\"\n",
    "\n",
    "    householdConstraints = (tract[150:166]).astype(int) #HOUSEHOLDS BY TYPE\n",
    "    hh_cnt = pd.Series(np.zeros(11),dtype=int) #11 household types (group quarters are not household)\n",
    "\n",
    "    # husband/wife families\n",
    "    # husband-wife family DP0130004 - DP0130005: Husband-wife family - With own children under 18 years\n",
    "    hh_cnt[0] = householdConstraints[4] - householdConstraints[5]; \n",
    "    # husband-wife family DP0130005, OWN CHILDREN < 18\n",
    "    hh_cnt[1] = householdConstraints[5]; \n",
    "    \n",
    "    # male householders\n",
    "    # single male householder DP0130006 - DP0130007: Male householder, no wife present - Male householder, no wife present\n",
    "    hh_cnt[2] = householdConstraints[6] - householdConstraints[7]; \n",
    "    # single male householder DP0130007, OWN CHILDREN < 18\n",
    "    hh_cnt[3] = householdConstraints[7];\n",
    "    \n",
    "    # female householders\n",
    "    # single female householder DP0130008 - DP0130009: Female householder, no husband present - With own children under 18 years\n",
    "    \n",
    "    # single female householder DP0130009, OWN CHILDREN < 18\n",
    "    hh_cnt[4] = householdConstraints[8] - householdConstraints[9]; # single female householder\n",
    "    hh_cnt[5] = householdConstraints[9]; # single female householder, OWN CHILDREN < 18\n",
    "    \n",
    "    \n",
    "    # nonfamily householder\n",
    "    hh_cnt[6] = householdConstraints[10] - householdConstraints[11]; # nonfamily group living\n",
    "    hh_cnt[7] = householdConstraints[12] - householdConstraints[13]; # lone male < 65\n",
    "    hh_cnt[8] = householdConstraints[13]; # lone male >= 65\n",
    "    hh_cnt[9] = householdConstraints[14] - householdConstraints[15]; # lone female < 65\n",
    "    hh_cnt[10] = householdConstraints[15]; # lone female >= 65\n",
    "\n",
    "    return hh_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate household members based on hhold type\n",
    "def gen_households(hh_type, people, mask):\n",
    "    \"\"\"\n",
    "    Eleven household types:\n",
    "    0         h&w (no<18) husband and wife no kids\n",
    "    1      h&w&ch (ch<18) husband and wife with kids\n",
    "    2        male (no<18) male with no kids (wife not present)\n",
    "    3        male (ch<18) male with kids (wife not present)\n",
    "    4      female (no<18) female with no kids (husband not present)\n",
    "    5      female (ch<18) female with kids (husband not present) \n",
    "    6     nonfamily group \n",
    "    7       lone male <65 male younger than 65 lives alone \n",
    "    8       lone male >65 male older than 65 lives alone\n",
    "    9      lone female<65 female younger than 65 lives alone\n",
    "    10     lone female>65 female older than 65 lives alone\n",
    "    \"\"\"\n",
    "    #create a list to hold household member\n",
    "    members = []\n",
    "    \n",
    "    \n",
    "\n",
    "    #first, create household head, 11 types\n",
    "    #age range of the householder for each household type  (the range comes from dp age range above)\n",
    "    head_ranges = [\n",
    "                    range(4,18), range(4,14), range(4,18), range(4,14),range(22,36), range(22,30),\n",
    "                    #6\n",
    "                    chain(range(4,18),range(21,36)),  \n",
    "                    range(4,13), range(13,18), range(21,31), range(31,36)\n",
    "                  ]\n",
    " \n",
    "    '''\n",
    "        meaning of the head_ranges: \n",
    "        [(15,99)/m/hh0,(20,70)/m/hh1,(15,99)/m/hh2,(20,70)/m/hh3,(15,99)/f/hh0,(20,70)/f/hh1,\n",
    "        (15,99)/f/hh4,(15,65)/f/hh5,(20,65)/m/hh7,(65,99)/m/hh8,(15,65)/f/hh9,(65,99)/f/hh10]\n",
    "        \n",
    "        head_sex:\n",
    "        [(1'm'),(2'm'),(3'm'),(4'm'),(5'f'),(6'f'),(7'f'),(8'f'),(9'm'),(10'm'),(11'f'),(12'f')]\n",
    "\n",
    "    ''' \n",
    "    #add the householder\n",
    "    pot = people[mask].code #potential's age or age group\n",
    "    \n",
    "    #selcet households head\n",
    "    iindex = pot[pot.isin(head_ranges[hh_type])].index[0] #potential's age is in the range of this hh type\n",
    "    # what is hh_type\n",
    "    \n",
    "    \n",
    "    h1 = people.loc[iindex] #age & sex of h1, what is h1\n",
    "    \n",
    "    mask[iindex] = False\n",
    "    members.append(iindex)\n",
    "\n",
    "    #if living alone then return the members\n",
    "    if hh_type > 6:\n",
    "        return members\n",
    "\n",
    "    #if husband and wife, add the wife\n",
    "    if hh_type in (0,1):\n",
    "        pot = people[mask].code\n",
    "        if h1.code == 4: #if husband is 20~24\n",
    "            iindex = pot[pot.isin(range(h1.code+17,h1.code+20))].index[0] #wife is -4~14 + husband age\n",
    "        else: # if husband is older than 20~24\n",
    "            iindex = pot[pot.isin(range(h1.code+16,h1.code+20))].index[0] \n",
    "        h2 = people.loc[iindex] # -4 < husband.age - wife.age < 9\n",
    "        mask[iindex] = False\n",
    "        members.append(iindex)\n",
    "\n",
    "\n",
    "    \"\"\"A child includes a son or daughter by birth (biological child), a stepchild,\n",
    "    or an adopted child of the householder, regardless of the child’s age or marital status.\n",
    "    The category excludes sons-in-law, daughters- in-law, and foster children.\"\"\"\n",
    "    #household types with at least one child (18-)\n",
    "    if hh_type in (1,3,5):\n",
    "        #https://www.census.gov/hhes/families/files/graphics/FM-3.pdf\n",
    "        if hh_type == 1:\n",
    "            num_of_child = max(1,abs(int(np.random.normal(2)))) #gaussian touch\n",
    "        elif hh_type == 3:\n",
    "            num_of_child = max(1,abs(int(np.random.normal(1.6)))) #gaussian touch\n",
    "        elif hh_type == 5:\n",
    "            num_of_child = max(1,abs(int(np.random.normal(1.8)))) #gaussian touch\n",
    "\n",
    "        pot = people[mask]\n",
    "        if hh_type == 1:\n",
    "            iindices = pot[(pot.age<18) & (45>h2.age-pot.age)].index[:num_of_child]\n",
    "        else: #father (mother) and child age difference not to exceed 50 (40)\n",
    "            age_diff = 45 if hh_type == 5 else 55\n",
    "            iindices = pot[(pot.age<18) & (age_diff>h1.age-pot.age)].index[:num_of_child]\n",
    "        for i in iindices:\n",
    "            child = people.loc[i]\n",
    "            mask[i] = False\n",
    "            members.append(i)\n",
    "\n",
    "    #if nonfamily group then either friends or unmarried couples\n",
    "    if hh_type == 6:\n",
    "        pot = people[mask].code\n",
    "        num_of_friends = max(1,abs(int(np.random.normal(1.3)))) #gaussian touch\n",
    "        iindices = pot[pot.isin(range(h1.code-2,h1.code+3))].index[:num_of_friends]\n",
    "        for i in iindices:\n",
    "            friend = people.loc[i]\n",
    "            mask[i] = False\n",
    "            members.append(i)\n",
    "\n",
    "    return members\n",
    "\n",
    "\n",
    "def populate_households(tract, people, hholds):\n",
    "    \n",
    "    #What is the mask for?\n",
    "    mask = pd.Series(True, index = people.index) #[True]*len(people)\n",
    "    \n",
    "    hholds['members'] = hholds.htype.apply(gen_households,args=(people, mask,))\n",
    "    \n",
    "\n",
    "    \"\"\"The seven types of group quarters are categorized as institutional group quarters\n",
    "    (correctional facilities for adults, juvenile facilities, nursing facilities/skilled-nursing facilities,\n",
    "    and other institutional facilities) or noninstitutional group quarters (college/university student housing,\n",
    "    military quarters, and other noninstitutional facilities).\"\"\"\n",
    "    \n",
    "    group_population = int(tract.DP0120014) #people living in group quarters (not in households)\n",
    "    \n",
    "    #gq_indices = people[(people.age>=65) | (people.age<18)].index[:group_population]\n",
    "    gq_indices = people[mask].index[:group_population]\n",
    "    \n",
    "    #for i in gq_indices: mask[i] = False\n",
    "    mask.loc[gq_indices] = False\n",
    "\n",
    "    #now distribute the remaining household guys as relatives...\n",
    "    relatives = people[mask].index\n",
    "    it = iter(relatives) #sample by replacement\n",
    "    relative_hhs = hholds[hholds.htype<7].sample(n=len(relatives),replace=True)\n",
    "    relative_hhs.members.apply(lambda x: x.append(next(it))) #appends on mutable lists\n",
    "    #for i in relatives: mask[i] = False\n",
    "    mask.loc[relatives]= False\n",
    "    #print('is anyone left homeless:',any(mask))\n",
    "    #add those living in group quarters as all living in a house of 12th type\n",
    "    if group_population > 0:\n",
    "        hholds.loc[len(hholds)] = {'htype':11, 'members':gq_indices}\n",
    "    \n",
    "    # name households\n",
    "    hholds = hholds.set_index(tract.name+'h'+pd.Series(np.arange(len(hholds)).astype(str)))\n",
    "\n",
    "    ## where is hh???\n",
    "    def hh_2_people(hh,people):\n",
    "        for m in hh.members:\n",
    "            people.loc[m,'hhold'] = hh.name\n",
    "            people.loc[m,'htype'] = hh.htype\n",
    "    \n",
    "    hholds.apply(hh_2_people,args=(people,),axis=1)\n",
    "    people['htype'] = people.htype.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Assign workplaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_workplaces(tract,people,od):\n",
    "    \"\"\"\n",
    "    if the destination tract of a worker is not in our DP dataset\n",
    "    then we assign his wp to 'DTIDw', otherwise 'DTIDw#'\n",
    "    \n",
    "    the actual size distribution of establishments is lognormal\n",
    "    https://www.princeton.edu/~erossi/fsdae.pdf\n",
    "    \"\"\"\n",
    "    #destination tracts and numbers\n",
    "    td = od[od['home'] == tract.name].set_index('work').S000\n",
    "    td = (td*tract.portion).apply(np.ceil).astype(int) #from this tract to others\n",
    "    # 58.5%: US population (16+) - employment rate\n",
    "    # https://data.bls.gov/timeseries/LNS12300000\n",
    "    employed = people[people.age>=18].sample(td.sum()).index #get the employed\n",
    "    dtract = pd.Series(np.repeat(td.index.values, td.values)) #get the destination tract\n",
    "    # if 'wp' in people.columns: people.drop('wp',axis=1,inplace=True)\n",
    "    people.loc[employed,'wp'] = dtract.apply(lambda x: x+'w'+str(np.random.choice(dp.loc[x,'WP_CNT'],p=dp.loc[x,'WP_PROBA'])) if x in dp.index else x+'w').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4, Get errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(tract,people):\n",
    "    \"\"\"Percentage errors\n",
    "    \"\"\"\n",
    "    err = {}    \n",
    "    #portion = tract.geometry.area / tract.Shape_Area # what portion of the tract is included\n",
    "    #senior_actual = int(tract.DP0150001 * portion) # Households with individuals 65 years and over\n",
    "    senior_actual = int(tract.DP0150001)\n",
    "    #minor_actual = int(tract.DP0140001 * portion) # Households with individuals under 18 years\n",
    "    minor_actual = int(tract.DP0140001)\n",
    "#     err['tract'] = tract.name\n",
    "    err['population'] = tract.DP0010001\n",
    "    err['in_gq'] = tract.DP0120014\n",
    "    avg_synthetic_family = people[people.htype<6].groupby('hhold').size().mean()\n",
    "    err['avg_family'] = 100*(avg_synthetic_family - tract.DP0170001) / tract.DP0170001\n",
    "    err['avg_hh'] = 100*(people[people.htype!=11].groupby('hhold').size().mean() - tract.DP0160001) / tract.DP0160001 \n",
    "    err['senior_hh'] = 100*(people[people.age>=65].hhold.nunique() - senior_actual) / senior_actual\n",
    "    err['minor_hh'] = 100*(people[people.age<18].hhold.nunique() - minor_actual) / minor_actual\n",
    "    return pd.Series(err,name=tract.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5, Create geo locations for each individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create space\n",
    "#shapely geometries are not hashable, here is my hash function to check the duplicates\n",
    "def hash_geom(x):\n",
    "    if x.geom_type == 'MultiLineString':\n",
    "        return tuple((round(lat,6),round(lon,6)) for s in x for lat,lon in s.coords[:])    \n",
    "    else:\n",
    "        return tuple((round(lat,6),round(lon,6)) for lat,lon in x.coords[:])\n",
    "    \n",
    "# create spaces\n",
    "def create_spaces(tract, hcnt, od, road, HD=0.0005, WD=0.0002):\n",
    "    #portion = tract.geometry.area / tract.Shape_Area # what portion of the tract is included\n",
    "    # create houses\n",
    "    # DP0180001: Total housing units, DP0180002: Occupied housing units\n",
    "    # hcnt = int(tract.DP0180002 * portion) #number of households DP0130001 == DP0180002\n",
    "    if tract.DP0120014 > 0: hcnt += 1 #people living in group quarters (not in households)\n",
    "    mask = road.intersects(tract.geometry) \n",
    "    hmask = mask & road.MTFCC.str.contains('S1400|S1740')\n",
    "    hrd = road[hmask].intersection(tract.geometry)\n",
    "    hrd = hrd[hrd.geom_type.isin(['LinearRing', 'LineString', 'MultiLineString'])]\n",
    "    hrd = hrd[~hrd.apply(hash_geom).duplicated()]\n",
    "    houses = hrd.apply(lambda x: pd.Series([x.interpolate(seg) for seg in np.arange(HD,x.length,HD)]))\n",
    "    houses = houses.unstack().dropna().reset_index(drop=True) #flatten\n",
    "    houses = houses.sample(n=hcnt,replace=True).reset_index(drop=True)\n",
    "    houses.index = tract.name + 'h' + houses.index.to_series().astype(str)\n",
    "    #create workplaces\n",
    "    #jcnt = int(portion * od[od.work==tract.name].S000.sum() / avg_wp)\n",
    "    wmask = mask & road.MTFCC.str.contains('S1200')\n",
    "    wrd = road[wmask].intersection(tract.geometry)\n",
    "    wrd = wrd[wrd.geom_type.isin(['LinearRing', 'LineString', 'MultiLineString'])]\n",
    "    wrd = wrd[~wrd.apply(hash_geom).duplicated()]\n",
    "    #workplaces on S1200\n",
    "    swps = wrd.apply(lambda x: pd.Series([x.interpolate(seg) for seg in np.arange(x.length,WD)]))\n",
    "    #workplaces on the joints of S1400|S1740\n",
    "    rwps = hrd.apply(lambda x: Point(x.coords[0]) if type(x) != MultiLineString else Point(x[0].coords[0]))\n",
    "    if len(swps) > 0:\n",
    "        wps = rwps.append(swps.unstack().dropna().reset_index(drop=True))\n",
    "    else:\n",
    "        wps=rwps\n",
    "    wps = wps.sample(n=tract.WP_CNT,replace=True).reset_index(drop=True)\n",
    "    wps.index = tract.name + 'w' + wps.index.to_series().astype(str)\n",
    "    return gpd.GeoSeries(houses), gpd.GeoSeries(wps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Main synthesize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(tract, od, road, errors, population, wps):\n",
    "    start_time = timeit.default_timer()\n",
    "    print(tract.name,'started...',end=' ')\n",
    "\n",
    "    try:\n",
    "        people = create_individuals(tract)\n",
    "        create_households(tract,people)\n",
    "        assign_workplaces(tract,people,od)\n",
    "        houses, wp = create_spaces(tract, people.hhold.nunique(), od, road)\n",
    "        people['geometry'] = people.hhold.map(houses)\n",
    "        err = get_errors(tract,people)\n",
    "        \n",
    "        wps.append(wp)\n",
    "        population.append(people)\n",
    "        errors.append(err)\n",
    "        \n",
    "    except:\n",
    "        print(tract.name,\" has problems\")\n",
    "        fd = open('Results/problematic_tracts.csv','a')\n",
    "        fd.write(tract.name)\n",
    "        fd.close()\n",
    "    print(tract.name,'now ended ({:.1f} secs)'.format(timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4, Apply above functions to generate Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list to hold population\n",
    "population = []\n",
    "#hold error\n",
    "errors = []\n",
    "#hold workplaces info\n",
    "wps = []\n",
    "\n",
    "#Test Code\n",
    "data = dp[0:2]\n",
    "data.apply(lambda t: synthesize(t,od,road,errors, population, wps),axis=1);\n",
    "\n",
    "#Main Apply, Whole Study Area, apply those funtion on each line of the processed cenese tract data\n",
    "#dp.apply(lambda t: synthesize(t,od,road,errors, population, wps),axis=1);\n",
    "\n",
    "#Hold the resutls in pickles for later ectraction, which will save memory\n",
    "with open('Results/'+\"errors\"+\"3000\"+\".pkl\", 'wb') as f:\n",
    "    pickle.dump(errors, f)\n",
    "with open('Results/'+\"population\"+\"3000\"+\".pkl\", 'wb') as f:\n",
    "    pickle.dump(population, f)\n",
    "with open('Results/'+\"wps\"+\"3000\"+\".pkl\", 'wb') as f:\n",
    "    pickle.dump(wps, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert Population to Pandas Data Frame\n",
    "df = pd.DataFrame()\n",
    "for i in population:\n",
    "    df = df.append(i)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workplaces\n",
    "wp  = pd.DataFrame()\n",
    "for j in wps:\n",
    "    wp = wp.append(j, ignore_index=True)\n",
    "wp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Errors\n",
    "er = pd.DataFrame()\n",
    "for e in errors:\n",
    "    er = er.append(e, ignore_index=True)\n",
    "er.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2, Save files\n",
    "df.to_csv('full_population.csv')\n",
    "wp.to_csv('full_workplaces.csv')\n",
    "er.to_csv('full_errors.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
